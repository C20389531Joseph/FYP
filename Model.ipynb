{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a119a7-2f86-461c-be22-71d284d3d419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06cfc507-3983-43ac-8bf4-bb2e8bf17e81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - loss: 5.9591 - mae: 1.9845 - val_loss: 5.6221 - val_mae: 1.9108\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 795ms/step - loss: 5.2399 - mae: 1.8412 - val_loss: 3.7291 - val_mae: 1.4927\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 798ms/step - loss: 3.2166 - mae: 1.4204 - val_loss: 2.0056 - val_mae: 1.1947\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 788ms/step - loss: 1.7031 - mae: 1.1099 - val_loss: 1.1892 - val_mae: 0.8994\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 789ms/step - loss: 0.9702 - mae: 0.7999 - val_loss: 0.7402 - val_mae: 0.6578\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 771ms/step - loss: 0.5674 - mae: 0.5856 - val_loss: 0.5684 - val_mae: 0.4936\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 782ms/step - loss: 0.4455 - mae: 0.4366 - val_loss: 0.4912 - val_mae: 0.3738\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 792ms/step - loss: 0.3463 - mae: 0.3224 - val_loss: 0.4755 - val_mae: 0.3317\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 822ms/step - loss: 0.3678 - mae: 0.2894 - val_loss: 0.4586 - val_mae: 0.3023\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 872ms/step - loss: 0.4921 - mae: 0.3196 - val_loss: 0.4351 - val_mae: 0.2440\n",
      "Model trained and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import docx\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Function to load answers from Word documents\n",
    "def load_answers_from_docs(doc_files):\n",
    "    questions = []\n",
    "    answers = []\n",
    "    scores = []\n",
    "    \n",
    "    for doc_file in doc_files:\n",
    "        doc = docx.Document(doc_file)\n",
    "        for paragraph in doc.paragraphs:\n",
    "            if paragraph.text.startswith(\"Q\"):  # Assume question text starts with \"Q\"\n",
    "                questions.append(paragraph.text) # store questions\n",
    "            elif paragraph.text.startswith(\"A\"):  # Assume answer text starts with \"A\"\n",
    "                answers.append(paragraph.text[2:].strip())  # Skip \"A:\". store answers\n",
    "            elif paragraph.text.startswith(\"Score\"):  # Assume score starts with \"Score:\"\n",
    "                scores.append([float(x) for x in paragraph.text.split(\":\")[1].strip().split(\",\")]) # store marking scheme\n",
    "    return questions, answers, scores\n",
    "\n",
    "# Load dataset\n",
    "doc_files = [\"Paper1.docx\", \"Paper2.docx\", \"Paper3.docx\", \"Paper4.docx\", \"Paper5.docx\", \"Paper6.docx\", \"Paper7.docx\", \"Paper8.docx\", \"Paper9.docx\", \"Paper10.docx\"]\n",
    "questions, answers, scores = load_answers_from_docs(doc_files)\n",
    "\n",
    "# Preprocess text: Tokenization and padding\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(answers)\n",
    "answers_seq = tokenizer.texts_to_sequences(answers)\n",
    "answers_pad = tf.keras.preprocessing.sequence.pad_sequences(answers_seq, maxlen=500) # maxlen = max number of documents. Set to 500\n",
    "\n",
    "# Convert scores to NumPy array for model compatibility\n",
    "max_categories = 5 # Categories for marking scheme, e.g. Grammer, explainition, or example.\n",
    "padded_scores = [] # used to fill out excess categories\n",
    "\n",
    "for score in scores:\n",
    "    # Pad with zeros or NaNs if the score list is shorter than max_categories\n",
    "    if len(score) < max_categories:\n",
    "        score += [0] * (max_categories - len(score))  # Padding with zeros\n",
    "    padded_scores.append(score)\n",
    "\n",
    "# Convert to numpy array to avoid breaking code\n",
    "scores = np.array(padded_scores)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(answers_pad, scores, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=500),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.5), # prevent overfitting of model\n",
    "    LSTM(32),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(score), activation='linear')  # Output matches the rubric categories. i.e. if 4 cate there will be 4 scored metrics. score comes fromfor loop.\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', # alan optimizer is used for training\n",
    "              loss='mean_squared_error', # mean_squared_error is used for regression tasks\n",
    "              metrics=['mae']) # Mean absolute error is used for trsining evaluation\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "          epochs=10, # itations of training\n",
    "          batch_size=32)\n",
    "\n",
    "# Save the model as a keras file\n",
    "model.save(\"essay_grading_model.keras\")\n",
    "\n",
    "# Final test and notification that process is finished\n",
    "print(\"Model trained and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5cb7cb6-1910-4abc-8ccd-59d2ec4ac2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Preprocessed essay shape: (1, 500)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predicted Scores: [[ 0.9702759   2.199916    3.1293108   3.2702675  -0.00480052]]\n",
      "\n",
      "Grading Results: [4. 5. 4. 4. 0.]\n",
      "Grammar: 0.97: Poor, needs improvement\n",
      "Coherence: 2.20: Poor, needs improvement\n",
      "Content Depth: 3.13: Good\n",
      "Example: 3.27: Good\n",
      "Language Clarity: -0.00: Nothing\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import docx\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import os \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"essay_grading_model.keras\")\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "training_answers = answers\n",
    "tokenizer.fit_on_texts(training_answers)\n",
    "\n",
    "# Function to load and preprocess a new essay\n",
    "def preprocess_new_essay(doc_file, tokenizer, max_len=500):\n",
    "    # Step 1: Load the text from the .docx file\n",
    "    doc = docx.Document(doc_file)\n",
    "    essay_text = \"\"\n",
    "    for paragraph in doc.paragraphs:\n",
    "        essay_text += paragraph.text.strip() + \" \"\n",
    "    \n",
    "    # Step 2: Tokenize and pad the text\n",
    "    sequence = tokenizer.texts_to_sequences([essay_text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post')\n",
    "    \n",
    "    return padded_sequence\n",
    "\n",
    "# Entry of the new essay\n",
    "new_essay_file = \"testanswer.docx\"  # In same folder\n",
    "# process essay\n",
    "padded_sequence = preprocess_new_essay(new_essay_file, tokenizer)\n",
    "\n",
    "# Predict the rubric scores, i.e. grade answers\n",
    "predicted_scores = model.predict(padded_sequence)\n",
    "\n",
    "# Marked outputs. Used for Demo will replace in final version\n",
    "rubric_categories = [\"Grammar\", \"Coherence\", \"Content Depth\", \"Examples\", \"Language Clarity\"]  # Adjust based on your rubric\n",
    "max_scores = np.max(y_train, axis=0)\n",
    "\n",
    "print(\"\\nGrading Limits:\", max_scores)\n",
    "for i, score in enumerate(predicted_scores[0]):\n",
    "    max_score = max_scores[i]  # Maximum score for the category\n",
    "    # Error checking. Check for zero max_score\n",
    "    if max_score == 0:\n",
    "        percentage = 0  # Set the percentage to 0 if max_score is 0\n",
    "        evaluation = \"Nothing or Terribly answered\"\n",
    "        print(f\"{rubric_categories[i]}: {score:.2f}: {evaluation}\")\n",
    "    else:\n",
    "        percentage = (score / max_score) * 100  # Calculate percentage score\n",
    "        if percentage == 100:\n",
    "            evaluation = \"Excellent\"\n",
    "        if percentage >= 50:\n",
    "            evaluation = \"Good\"\n",
    "        else:\n",
    "            evaluation = \"Poor, needs improvement\"\n",
    "        print(f\"{rubric_categories[i]}: {score:.2f}: {evaluation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b325f6-deef-4a11-883d-8f07c2e9d9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
